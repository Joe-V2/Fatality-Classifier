{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining ACW: Coding Submission\n",
    "\n",
    "--IMPORTANT! Before running, ensure SciKit-learn and Pandas are installed properly! This script was written with Python 3.7.3, 32-bit.--\n",
    "\n",
    "\n",
    "## Step 1: Importing our Libraries and Raw Data\n",
    "\n",
    "Below, you can see the data we've read in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting to work...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import seaborn as sb\n",
    "import math\n",
    "print(\"Getting to work...\")\n",
    "rawData = pd.read_csv('ACWData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random</th>\n",
       "      <th>Id</th>\n",
       "      <th>IPSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1520.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>1516.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509545</td>\n",
       "      <td>188365.022368</td>\n",
       "      <td>78.872032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.284006</td>\n",
       "      <td>64355.870242</td>\n",
       "      <td>10.162351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>78261.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.268531</td>\n",
       "      <td>137130.750000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.517616</td>\n",
       "      <td>191344.500000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.754724</td>\n",
       "      <td>244559.500000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999448</td>\n",
       "      <td>295978.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Random             Id         IPSI\n",
       "count  1520.000000    1520.000000  1516.000000\n",
       "mean      0.509545  188365.022368    78.872032\n",
       "std       0.284006   64355.870242    10.162351\n",
       "min       0.000295   78261.000000    35.000000\n",
       "25%       0.268531  137130.750000    73.000000\n",
       "50%       0.517616  191344.500000    77.000000\n",
       "75%       0.754724  244559.500000    85.000000\n",
       "max       0.999448  295978.000000    99.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Data Cleaning\n",
    "\n",
    "Next, a second data frame is created to house only entries that adhere to specified data taxonomy,\n",
    "as well as another to hold entries with erroneous feature values, to ensure all problematic samples have been removed.\n",
    "Duplicate entries will also be removed to prevent interference with classification later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData = rawData.copy()\n",
    "cleanData['Indication'] = cleanData['Indication'].str.upper()\n",
    "cleanData['IPSI'] = pd.to_numeric(cleanData['IPSI'] , errors='coerce', downcast='float')\n",
    "cleanData['Contra'] = pd.to_numeric(cleanData['Contra'] , errors='coerce', downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "badData = pd.DataFrame(columns = cleanData.columns)\n",
    "badData_ref = cleanData.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in badData_ref.iterrows():\n",
    "    for columns in badData_ref :\n",
    "        if ((row[columns]))  :\n",
    "            badData = badData.append((cleanData.loc[[index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random</th>\n",
       "      <th>Id</th>\n",
       "      <th>IPSI</th>\n",
       "      <th>Contra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1502.000000</td>\n",
       "      <td>1502.000000</td>\n",
       "      <td>1502.000000</td>\n",
       "      <td>1502.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509369</td>\n",
       "      <td>188063.770306</td>\n",
       "      <td>78.832886</td>\n",
       "      <td>56.69574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.284234</td>\n",
       "      <td>64454.253880</td>\n",
       "      <td>10.163915</td>\n",
       "      <td>29.52651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000295</td>\n",
       "      <td>78261.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.268254</td>\n",
       "      <td>135885.250000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>30.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.516824</td>\n",
       "      <td>191053.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.754513</td>\n",
       "      <td>244417.500000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999448</td>\n",
       "      <td>295978.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Random             Id         IPSI      Contra\n",
       "count  1502.000000    1502.000000  1502.000000  1502.00000\n",
       "mean      0.509369  188063.770306    78.832886    56.69574\n",
       "std       0.284234   64454.253880    10.163915    29.52651\n",
       "min       0.000295   78261.000000    35.000000    10.00000\n",
       "25%       0.268254  135885.250000    73.000000    30.00000\n",
       "50%       0.516824  191053.000000    77.000000    50.00000\n",
       "75%       0.754513  244417.500000    85.000000    85.00000\n",
       "max       0.999448  295978.000000    99.000000   100.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData = cleanData.dropna()\n",
    "cleanData = cleanData.drop_duplicates(subset='Id')\n",
    "cleanData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As promised, you can see how the for loop above iterates over all  1,520 items in the table, comparing them against another dataframe of reference boolean values - denoting the presence of any null-value attributes. \n",
    "The resultant tables include cleanData which holds only clean non-erroneous values, badData which only holds entries with null or unknown values, and badData_ref which acts as a flag table for finding null values.\n",
    "Once one is detected, the index of that value is read from its row, and the corresponding row in the clean data frame is added to the bank of bad data. Dropped from the clean data frame entirely, it will later be added back to a composite of the two frames when the missing values are repaired.\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Removing Outliers\n",
    "\n",
    "The following few lines build a series of additional dataframes to isolate either of the two given classes.\n",
    "This is used for ease of comparison, and validation for debugging purposes.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cDataOutFree = cleanData.copy()\n",
    "cDataOutFreeR = cDataOutFree.copy().where(cDataOutFree.label == 'Risk')\n",
    "cDataOutFreeNR = cDataOutFree.copy().where(cDataOutFree.label == 'NoRisk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll compare the difference between given IPSI and Contra values,\n",
    "and the means in both global and class-specific contexts. Each class\n",
    "of data has been partitioned to its own table, so the values of any numeric\n",
    "features are analysed according to means and standard deviations read from\n",
    "a similar reference frame.<br>\n",
    "\n",
    "Both of the data frames containing class specific data are then merged into one frame,\n",
    "removing duplicates to ensure integrity in representing a cleaned set with respect to\n",
    "original raw values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cDataOutFree = cDataOutFree[abs(cDataOutFree.IPSI-cDataOutFree.IPSI.mean()) <= (3*cleanData.IPSI.std())]\n",
    "cDataOutFree = cDataOutFree.append(cDataOutFree[abs(cDataOutFree.Contra-cDataOutFree.Contra.mean()) <= (3*cleanData.Contra.std())])\n",
    "cDataOutFree = cDataOutFree.drop_duplicates(subset='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cDataOutFreeR = cDataOutFreeR[abs(cDataOutFreeR.IPSI-cDataOutFreeR.IPSI.mean()) <= (3*(cleanData.where(cleanData.label == 'Risk')).IPSI.std())]\n",
    "cDataOutFreeR = cDataOutFreeR.append(cDataOutFreeR[abs(cDataOutFreeR.Contra-cDataOutFreeR.Contra.mean()) <= (3*(cleanData.where(cleanData.label == 'Risk')).Contra.std())])\n",
    "cDataOutFreeNR = cDataOutFreeNR[abs(cDataOutFreeNR.IPSI-cDataOutFreeNR.IPSI.mean()) <= (3*(cleanData.where(cleanData.label == 'NoRisk')).IPSI.std())]\n",
    "cDataOutFreeNR = cDataOutFreeNR.append(cDataOutFreeNR[abs(cDataOutFreeNR.Contra-cDataOutFreeNR.Contra.mean()) <= (3*(cleanData.where(cleanData.label == 'Risk')).Contra.std())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cDataOutFreeCR = cDataOutFreeR.append(cDataOutFreeNR) \n",
    "cDataOutFreeCR = cDataOutFree.drop_duplicates(subset='Id')\n",
    "cDataOutFreeCR = cDataOutFreeCR.sort_index()"
   ]
  },
  {
   "source": [
    "\n",
    "## Step 4: Transforms\n",
    "\n",
    "Now we have our clean sets with all outliers removed, we need to make them numeric so any classifier we use can make sense of them.<br>\n",
    "\n",
    "Rather than defining individual data frames for each of the sets we have,\n",
    "it would be much easier to make a function that takes a given data frame and \n",
    "performs all the transforms we need. That way, it can be called whenever a\n",
    "classifier needs to perform.\n",
    "\n",
    "### numGen\n",
    "\n",
    "To generate these figures in such a way, numGen is passed with a dataframe.\n",
    "Copying pre-formatted numeric columns across to a local dataframe variable,\n",
    "it then generates dummies from a copy of the supplied dataframe and drops\n",
    "all columns where 1 correlates to a 'no' value in any of our nominative types.\n",
    "It also transforms indication columns to four of individual binary values as\n",
    "well. \n",
    "- Parameters:\n",
    "    - data (dataframe object) - the array of data you want to transform.\n",
    "- Returns:\n",
    "    - numData (dataframe object) - a transformed array of data.\n",
    "\n",
    "### genMet\n",
    "\n",
    "In addition to this, it would be helpful to transform any performance metrics\n",
    "we get back into something more legible. This is what genMet does, taking a\n",
    "name, the corresponding dataframe object, any parameter descriptions of note,\n",
    "a predefined accuracy metric, confusion matrix ndarray and any graphical renderings.\n",
    "Using these, it generates metrics in a format matching our log table that will\n",
    "later be used to note any successes.\n",
    "- Parameters:\n",
    "    - data (string) - the name of the dataframe the supplied classifier has been fitted to.\n",
    "    - clf (classifier object) - a fitted classifier of any type.\n",
    "    - params (string) - any parameters of note to be attached to the results log entry.\n",
    "    - acc (float) - the accuracy associated with the supplied classifier's predictivity.\n",
    "    - matrix (ndarray) - the confusion matrix associated with the supplied classifier's predictions.   \n",
    "- Returns:\n",
    "    - cols (dataframe object) - formatted results for the supplied classifier to be added to the main results log."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numGen (data) :\n",
    "        numData = pd.get_dummies((data.copy())[['Indication','Diabetes', 'IHD', 'Hypertension', 'Arrhythmia', 'History']])\n",
    "        numData['IPSI'] = (data.copy())['IPSI']\n",
    "        numData['Contra'] = (data.copy())['Contra']\n",
    "        numData['label'] = (data.copy())['label']\n",
    "        numData = numData.drop(['Diabetes_no','IHD_no','Hypertension_no','Arrhythmia_no','History_no'], axis=1)\n",
    "        return numData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genMet (data, clf, params, acc, matrix):\n",
    "        \n",
    "        datName = data\n",
    "        clfType = str(clf).split('(')[0]\n",
    "        tp = matrix[0,0]\n",
    "        tn = matrix[1:,1:].sum()\n",
    "        fp = matrix[0,1:].sum()\n",
    "        fn = matrix[1:,0].sum()\n",
    "        tp = int(tp)\n",
    "        tn = int(tn)\n",
    "        fp = int(fp)\n",
    "        fn = int(fn)\n",
    "        acc = \"{:.4%}\".format(acc)\n",
    "        sens = zeroCatch(tp,(tp+fn))\n",
    "        spec = zeroCatch(tn,(tn+fp))\n",
    "        manhat = (1-sens)+(1-spec)\n",
    "        eucl = math.sqrt(math.pow((1-sens),2)+math.pow((1-spec),2))\n",
    "        print(\"Logged \" + datName + \" entry for \" + clfType + \" classifier, accuracy: \" + acc)\n",
    "        cols = {'Data Set':datName,'Classifier':clfType,'Parameters':params,'Accuracy':acc,'TP':tp,'TN':tn,'FP':fp,'FN':fn,'Spec':spec,'Sens':sens,'1-Spec':1-spec,'1-Sens':1-sens,'Manhattan':manhat,'Euclidian':eucl}\n",
    "        return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroCatch (a, b) :\n",
    "        return a / b if b else 0 #stops any dividing by zero nonsense!"
   ]
  },
  {
   "source": [
    "\n",
    "## Step 5: Modelling\n",
    "\n",
    "Finally, this function takes whatever dataframe is passed to it, as well as a\n",
    "string to identify any log entries pertaining to it. The function then initialises\n",
    "a uniform number of models every time, creates a 70/30 split training/test dataframes\n",
    "to use with them from the results of the numeric transformer written in the previous cell.\n",
    "This is then used to fit, predict and log the results from each of the classifiers initialised\n",
    "at the beginning using their standard parameters.\n",
    "\n",
    "\n",
    "### fitPredictData\n",
    "\n",
    "Takes a given data frame, splits it by a 70/30 ratio into training and test sets respectively,\n",
    "and fits three different types of classifiers to it, with eight permutations of parameters and meta-parameters.\n",
    "Then, using a local function to supply each one with a test set to predict, numGen and genMet are\n",
    "called to supply the appropriate entries for the results log for each individual classifier.\n",
    "\n",
    "- Parameters:\n",
    "    - argData (dataframe object) - the dataframe you want to classify.<br>\n",
    "    - dataName (string) - the name you want to use to refer to the dataframe in the results logs.<br>\n",
    "- Returns:\n",
    "    - resList (dataframe object) - the results log for each of the 8 classifier permutations, collated into a dataframe and sorted in order of execution.<br>\n",
    "\n",
    "### clfPredict\n",
    "\n",
    "Takes a given fitted model and a string containing any parameters to note in the results log.\n",
    "Predicts the model against a test set, and generates accuracy and confusion matrix metrics to\n",
    "supply to genMet to generate log entries for the respective classifier/data combination.\n",
    "\n",
    "- Parameters:\n",
    "    - model (classifier object) - the fully fitted model to generate performance metrics for.\n",
    "    - args (string) - any arguments of note supplied to the classifier that may affect its operation.\n",
    "\n",
    "- Returns:\n",
    "    - cols (dataframe object) - clfPredict calls genMet, and passes the returned object from that method< straight back to whatever called it. Probably bad practice, but syntactically keeps code working."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitPredictData(argData, dataName) :\n",
    "        data = ((numGen(argData.copy())))\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features = ['Indication_A-F', 'Indication_ASX', 'Indication_CVA', 'Indication_TIA', 'Diabetes_yes', 'IHD_yes', 'Hypertension_yes', 'Arrhythmia_yes', 'History_yes', 'IPSI', 'Contra',]\n",
    "        X = data.loc[:, features]\n",
    "        Y = le.fit_transform(data.label)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,shuffle=True)\n",
    "        tree = DecisionTreeClassifier()\n",
    "        km = KMeans(n_clusters=2, random_state=0)\n",
    "        mlp = MLPClassifier(max_iter=350)\n",
    "        metaTree = DecisionTreeClassifier(min_samples_split=8,max_depth=350)\n",
    "        metaKm = KMeans(n_clusters=2, n_init=650)\n",
    "        metaMlp = MLPClassifier(max_iter=700, activation='logistic')\n",
    "        adaT = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=4, max_depth=350),n_estimators=50,learning_rate=1)\n",
    "        bgK = BaggingClassifier(KMeans(n_clusters=2, n_init=350),n_estimators=50,max_features=11)\n",
    "        resList =  pd.DataFrame(columns=['Data Set', 'Classifier','Parameters','Accuracy','TP','TN','FP','FN','Spec','Sens','1-Spec','1-Sens','Manhattan','Euclidian'])\n",
    "    \n",
    "        tree = tree.fit(X_train, Y_train)\n",
    "        km = km.fit(X_train)\n",
    "        mlp = mlp.fit(X_train,Y_train)\n",
    "        metaTree = metaTree.fit(X_train,Y_train)\n",
    "        metaKm = metaKm.fit(X_train,Y_train)\n",
    "        metaMlp = metaMlp.fit(X_train,Y_train)\n",
    "    \n",
    "        \n",
    "        adaT = adaT.fit(X_train,Y_train)\n",
    "        bgK = bgK.fit(X_train,Y_train)\n",
    "        \n",
    "        print(\"Working on the next set of predictors...\")\n",
    "        def clfPredict (model, args) :\n",
    "                result = (model).predict(X_test)\n",
    "                accuracy = metrics.accuracy_score(Y_test,result)\n",
    "                matrix = metrics.confusion_matrix(Y_test,result)\n",
    "                \n",
    "                return genMet(dataName,model,args,accuracy,matrix)\n",
    "        resList = resList.append(clfPredict(tree,\"std\"), ignore_index=True)\n",
    "        resList = resList.append(clfPredict(km,\"std\"),ignore_index=True)\n",
    "        resList = resList.append(clfPredict(mlp,\"300 max iterations\"),ignore_index=True)\n",
    "        resList = resList.append(clfPredict(metaTree,\"350 max depth, 8 min split samples\"),ignore_index=True)\n",
    "        resList = resList.append(clfPredict(metaKm,\"350 max depth\"),ignore_index=True)\n",
    "        resList = resList.append(clfPredict(metaMlp, \"350 max iterations, logistic activator\"),ignore_index=True)\n",
    "        resList = resList.append(clfPredict(adaT,\"AdaBoosted Decision Tree\"),ignore_index=True)\n",
    "        resList = resList.append(clfPredict(bgK,\"Bagged KMeans\"),ignore_index=True)\n",
    "        return resList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, the classification function fitPredictData is called, using each of the dataframes we cleaned\n",
    "previously, which will be automatically transformed, split, and logged with a\n",
    "single function call. Once all data has been logged, the resultant dataframe writes to a .CSV\n",
    "file, located in the same directory as wherever the script has been run from.<br>\n",
    "\n",
    "It makes itself quite evident on repeated executions, but the KMeans classifier is incredibly inconsistent, which I suspect is due to how the training and test sets are passed to it. My attempts to mitigate against this have remained unsuccessful, but with the comparatively consistent success of other options, we are not without choice for implementation in a hypothetical deployment stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfList = pd.DataFrame(columns=['Data Set', 'Classifier','Parameters','Accuracy','TP','TN','FP','FN','Spec','Sens','1-Spec','1-Sens','Manhattan','Euclidian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\534288\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (350) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the next set of predictors...\n",
      "Logged cleanData entry for DecisionTreeClassifier classifier, accuracy: 99.3348%\n",
      "Logged cleanData entry for KMeans classifier, accuracy: 17.2949%\n",
      "Logged cleanData entry for MLPClassifier classifier, accuracy: 95.5654%\n",
      "Logged cleanData entry for DecisionTreeClassifier classifier, accuracy: 98.6696%\n",
      "Logged cleanData entry for KMeans classifier, accuracy: 82.4834%\n",
      "Logged cleanData entry for MLPClassifier classifier, accuracy: 97.1175%\n",
      "Logged cleanData entry for AdaBoostClassifier classifier, accuracy: 99.1131%\n",
      "Logged cleanData entry for BaggingClassifier classifier, accuracy: 82.4834%\n",
      "Working on the next set of predictors...\n",
      "Logged cDataOutFree entry for DecisionTreeClassifier classifier, accuracy: 98.8914%\n",
      "Logged cDataOutFree entry for KMeans classifier, accuracy: 17.7384%\n",
      "Logged cDataOutFree entry for MLPClassifier classifier, accuracy: 96.6741%\n",
      "Logged cDataOutFree entry for DecisionTreeClassifier classifier, accuracy: 98.8914%\n",
      "Logged cDataOutFree entry for KMeans classifier, accuracy: 82.2616%\n",
      "Logged cDataOutFree entry for MLPClassifier classifier, accuracy: 98.4479%\n",
      "Logged cDataOutFree entry for AdaBoostClassifier classifier, accuracy: 98.8914%\n",
      "Logged cDataOutFree entry for BaggingClassifier classifier, accuracy: 82.2616%\n",
      "Working on the next set of predictors...\n",
      "Logged cDataOutFreeCR entry for DecisionTreeClassifier classifier, accuracy: 98.8914%\n",
      "Logged cDataOutFreeCR entry for KMeans classifier, accuracy: 17.9601%\n",
      "Logged cDataOutFreeCR entry for MLPClassifier classifier, accuracy: 95.7871%\n",
      "Logged cDataOutFreeCR entry for DecisionTreeClassifier classifier, accuracy: 98.2262%\n",
      "Logged cDataOutFreeCR entry for KMeans classifier, accuracy: 17.9601%\n",
      "Logged cDataOutFreeCR entry for MLPClassifier classifier, accuracy: 95.5654%\n",
      "Logged cDataOutFreeCR entry for AdaBoostClassifier classifier, accuracy: 99.3348%\n",
      "Logged cDataOutFreeCR entry for BaggingClassifier classifier, accuracy: 81.8182%\n"
     ]
    }
   ],
   "source": [
    "clfList = clfList.append(fitPredictData(cleanData, 'cleanData'), ignore_index=True)\n",
    "clfList = clfList.append(fitPredictData(cDataOutFree, 'cDataOutFree'), ignore_index=True)\n",
    "clfList = clfList.append(fitPredictData(cDataOutFreeCR, 'cDataOutFreeCR'), ignore_index=True)\n",
    "export = clfList.to_csv(path_or_buf=r'results.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can see a table below this cell, all data has been processed, cleaned, modelled and classified. View the results in the file you ran this script from!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Spec</th>\n",
       "      <th>Sens</th>\n",
       "      <th>1-Spec</th>\n",
       "      <th>1-Sens</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Euclidian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>std</td>\n",
       "      <td>99.3348%</td>\n",
       "      <td>289</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>std</td>\n",
       "      <td>17.2949%</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>239</td>\n",
       "      <td>133</td>\n",
       "      <td>0.101504</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.718919</td>\n",
       "      <td>1.617415</td>\n",
       "      <td>1.150713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>300 max iterations</td>\n",
       "      <td>95.5654%</td>\n",
       "      <td>282</td>\n",
       "      <td>149</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.962457</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>0.094505</td>\n",
       "      <td>0.068221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>350 max depth, 8 min split samples</td>\n",
       "      <td>98.6696%</td>\n",
       "      <td>289</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.986348</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>0.026310</td>\n",
       "      <td>0.018617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>350 max depth</td>\n",
       "      <td>82.4834%</td>\n",
       "      <td>239</td>\n",
       "      <td>133</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>0.718919</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.101504</td>\n",
       "      <td>0.382585</td>\n",
       "      <td>0.298847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>350 max iterations, logistic activator</td>\n",
       "      <td>97.1175%</td>\n",
       "      <td>289</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.049912</td>\n",
       "      <td>0.038986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoosted Decision Tree</td>\n",
       "      <td>99.1131%</td>\n",
       "      <td>289</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.015871</td>\n",
       "      <td>0.012892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cleanData</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Bagged KMeans</td>\n",
       "      <td>82.4834%</td>\n",
       "      <td>239</td>\n",
       "      <td>133</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>0.718919</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.101504</td>\n",
       "      <td>0.382585</td>\n",
       "      <td>0.298847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>std</td>\n",
       "      <td>98.8914%</td>\n",
       "      <td>308</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.014701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>std</td>\n",
       "      <td>17.7384%</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>258</td>\n",
       "      <td>113</td>\n",
       "      <td>0.101045</td>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>1.587979</td>\n",
       "      <td>1.132640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>300 max iterations</td>\n",
       "      <td>96.6741%</td>\n",
       "      <td>303</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.971154</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.072012</td>\n",
       "      <td>0.051917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>350 max depth, 8 min split samples</td>\n",
       "      <td>98.8914%</td>\n",
       "      <td>308</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.014701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>350 max depth</td>\n",
       "      <td>82.2616%</td>\n",
       "      <td>258</td>\n",
       "      <td>113</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.101045</td>\n",
       "      <td>0.412021</td>\n",
       "      <td>0.326980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>350 max iterations, logistic activator</td>\n",
       "      <td>98.4479%</td>\n",
       "      <td>304</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.035097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoosted Decision Tree</td>\n",
       "      <td>98.8914%</td>\n",
       "      <td>308</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.014701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cDataOutFree</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Bagged KMeans</td>\n",
       "      <td>82.2616%</td>\n",
       "      <td>258</td>\n",
       "      <td>113</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.101045</td>\n",
       "      <td>0.412021</td>\n",
       "      <td>0.326980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>std</td>\n",
       "      <td>98.8914%</td>\n",
       "      <td>283</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>0.989510</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.022611</td>\n",
       "      <td>0.016030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>std</td>\n",
       "      <td>17.9601%</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>235</td>\n",
       "      <td>135</td>\n",
       "      <td>0.116541</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.883459</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>1.613188</td>\n",
       "      <td>1.145864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>300 max iterations</td>\n",
       "      <td>95.7871%</td>\n",
       "      <td>276</td>\n",
       "      <td>156</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.089510</td>\n",
       "      <td>0.064790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>350 max depth, 8 min split samples</td>\n",
       "      <td>98.2262%</td>\n",
       "      <td>282</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.981707</td>\n",
       "      <td>0.982578</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.017422</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.025261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>350 max depth</td>\n",
       "      <td>17.9601%</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>235</td>\n",
       "      <td>135</td>\n",
       "      <td>0.116541</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.883459</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>1.613188</td>\n",
       "      <td>1.145864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>350 max iterations, logistic activator</td>\n",
       "      <td>95.5654%</td>\n",
       "      <td>283</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>0.061269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoosted Decision Tree</td>\n",
       "      <td>99.3348%</td>\n",
       "      <td>284</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.009254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cDataOutFreeCR</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Bagged KMeans</td>\n",
       "      <td>81.8182%</td>\n",
       "      <td>235</td>\n",
       "      <td>134</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.880150</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>0.391589</td>\n",
       "      <td>0.296995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data Set              Classifier  \\\n",
       "0        cleanData  DecisionTreeClassifier   \n",
       "1        cleanData                  KMeans   \n",
       "2        cleanData           MLPClassifier   \n",
       "3        cleanData  DecisionTreeClassifier   \n",
       "4        cleanData                  KMeans   \n",
       "5        cleanData           MLPClassifier   \n",
       "6        cleanData      AdaBoostClassifier   \n",
       "7        cleanData       BaggingClassifier   \n",
       "8     cDataOutFree  DecisionTreeClassifier   \n",
       "9     cDataOutFree                  KMeans   \n",
       "10    cDataOutFree           MLPClassifier   \n",
       "11    cDataOutFree  DecisionTreeClassifier   \n",
       "12    cDataOutFree                  KMeans   \n",
       "13    cDataOutFree           MLPClassifier   \n",
       "14    cDataOutFree      AdaBoostClassifier   \n",
       "15    cDataOutFree       BaggingClassifier   \n",
       "16  cDataOutFreeCR  DecisionTreeClassifier   \n",
       "17  cDataOutFreeCR                  KMeans   \n",
       "18  cDataOutFreeCR           MLPClassifier   \n",
       "19  cDataOutFreeCR  DecisionTreeClassifier   \n",
       "20  cDataOutFreeCR                  KMeans   \n",
       "21  cDataOutFreeCR           MLPClassifier   \n",
       "22  cDataOutFreeCR      AdaBoostClassifier   \n",
       "23  cDataOutFreeCR       BaggingClassifier   \n",
       "\n",
       "                                Parameters  Accuracy   TP   TN   FP   FN  \\\n",
       "0                                      std  99.3348%  289  160    2    0   \n",
       "1                                      std  17.2949%   52   27  239  133   \n",
       "2                       300 max iterations  95.5654%  282  149    9   11   \n",
       "3       350 max depth, 8 min split samples  98.6696%  289  156    2    4   \n",
       "4                            350 max depth  82.4834%  239  133   52   27   \n",
       "5   350 max iterations, logistic activator  97.1175%  289  149    2   11   \n",
       "6                 AdaBoosted Decision Tree  99.1131%  289  159    2    1   \n",
       "7                            Bagged KMeans  82.4834%  239  133   52   27   \n",
       "8                                      std  98.8914%  308  138    1    4   \n",
       "9                                      std  17.7384%   51   29  258  113   \n",
       "10                      300 max iterations  96.6741%  303  133    6    9   \n",
       "11      350 max depth, 8 min split samples  98.8914%  308  138    1    4   \n",
       "12                           350 max depth  82.2616%  258  113   51   29   \n",
       "13  350 max iterations, logistic activator  98.4479%  304  140    5    2   \n",
       "14                AdaBoosted Decision Tree  98.8914%  308  138    1    4   \n",
       "15                           Bagged KMeans  82.2616%  258  113   51   29   \n",
       "16                                     std  98.8914%  283  163    2    3   \n",
       "17                                     std  17.9601%   50   31  235  135   \n",
       "18                      300 max iterations  95.7871%  276  156    9   10   \n",
       "19      350 max depth, 8 min split samples  98.2262%  282  161    3    5   \n",
       "20                           350 max depth  17.9601%   50   31  235  135   \n",
       "21  350 max iterations, logistic activator  95.5654%  283  148    2   18   \n",
       "22                AdaBoosted Decision Tree  99.3348%  284  164    1    2   \n",
       "23                           Bagged KMeans  81.8182%  235  134   50   32   \n",
       "\n",
       "        Spec      Sens    1-Spec    1-Sens  Manhattan  Euclidian  \n",
       "0   0.987654  1.000000  0.012346  0.000000   0.012346   0.012346  \n",
       "1   0.101504  0.281081  0.898496  0.718919   1.617415   1.150713  \n",
       "2   0.943038  0.962457  0.056962  0.037543   0.094505   0.068221  \n",
       "3   0.987342  0.986348  0.012658  0.013652   0.026310   0.018617  \n",
       "4   0.718919  0.898496  0.281081  0.101504   0.382585   0.298847  \n",
       "5   0.986755  0.963333  0.013245  0.036667   0.049912   0.038986  \n",
       "6   0.987578  0.996552  0.012422  0.003448   0.015871   0.012892  \n",
       "7   0.718919  0.898496  0.281081  0.101504   0.382585   0.298847  \n",
       "8   0.992806  0.987179  0.007194  0.012821   0.020015   0.014701  \n",
       "9   0.101045  0.310976  0.898955  0.689024   1.587979   1.132640  \n",
       "10  0.956835  0.971154  0.043165  0.028846   0.072012   0.051917  \n",
       "11  0.992806  0.987179  0.007194  0.012821   0.020015   0.014701  \n",
       "12  0.689024  0.898955  0.310976  0.101045   0.412021   0.326980  \n",
       "13  0.965517  0.993464  0.034483  0.006536   0.041019   0.035097  \n",
       "14  0.992806  0.987179  0.007194  0.012821   0.020015   0.014701  \n",
       "15  0.689024  0.898955  0.310976  0.101045   0.412021   0.326980  \n",
       "16  0.987879  0.989510  0.012121  0.010490   0.022611   0.016030  \n",
       "17  0.116541  0.270270  0.883459  0.729730   1.613188   1.145864  \n",
       "18  0.945455  0.965035  0.054545  0.034965   0.089510   0.064790  \n",
       "19  0.981707  0.982578  0.018293  0.017422   0.035714   0.025261  \n",
       "20  0.116541  0.270270  0.883459  0.729730   1.613188   1.145864  \n",
       "21  0.986667  0.940199  0.013333  0.059801   0.073134   0.061269  \n",
       "22  0.993939  0.993007  0.006061  0.006993   0.013054   0.009254  \n",
       "23  0.728261  0.880150  0.271739  0.119850   0.391589   0.296995  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}